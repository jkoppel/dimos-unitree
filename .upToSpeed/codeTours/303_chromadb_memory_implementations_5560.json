{
  "title": "30.3: ChromaDB Memory Implementations",
  "id": "pGRgJBBEZKRfUEKxaeOAMMfQQFItsdQr/Lkc0oFrdlY=",
  "originalId": 5560,
  "position": 115,
  "steps": [
    {
      "type": "textOnly",
      "description": "This walkthrough examines the `ChromaDB`-based semantic memory implementation in `dimos/agents/memory/chroma_impl.py`. We'll explore how the base `ChromaAgentSemanticMemory` class defines the `ChromaDB` integration patterns, and how two concrete implementations provide OpenAI and local embedding capabilities.",
      "title": "",
      "id": "69103"
    },
    {
      "type": "highlight",
      "description": "The base `ChromaAgentSemanticMemory` class establishes the foundation for **ChromaDB** integration. Notice how it inherits from `AbstractAgentSemanticMemory` and initializes key attributes that will be set by subclasses: `db_connection` for the **ChromaDB** client and `embeddings` for the embedding function.",
      "file": "dimos/agents/memory/chroma_impl.py",
      "highlight": [
        {
          "start": 24,
          "end": 32
        }
      ],
      "title": "",
      "id": "69104",
      "hideAreas": []
    },
    {
      "type": "highlight",
      "description": "The `create` method is declared as **abstract**, forcing each subclass to implement its own embedding setup and database initialization logic. This is where the key differences between OpenAI and local implementations will emerge.",
      "file": "dimos/agents/memory/chroma_impl.py",
      "highlight": [
        {
          "start": 38,
          "end": 41
        }
      ],
      "title": "",
      "id": "69105",
      "hideAreas": []
    },
    {
      "type": "highlight",
      "description": "The `add_vector` method demonstrates the `ChromaDB` integration pattern. It uses the `add_texts` method which automatically handles embedding generation through the configured embedding function, and includes metadata for each vector.",
      "file": "dimos/agents/memory/chroma_impl.py",
      "highlight": [
        {
          "start": 43,
          "end": 51
        }
      ],
      "title": "",
      "id": "69106",
      "hideAreas": []
    },
    {
      "type": "highlight",
      "description": "The `query` method shows `ChromaDB`'s flexibility for similarity search. It supports both standard similarity search and relevance score filtering. The conditional logic on lines 63-70 enables threshold-based filtering when needed, while lines 72-76 provide the simpler search variant.",
      "file": "dimos/agents/memory/chroma_impl.py",
      "highlight": [
        {
          "start": 58,
          "end": 76
        }
      ],
      "title": "",
      "id": "69107",
      "hideAreas": []
    },
    {
      "type": "highlight",
      "description": "The `delete_vector` method completes the CRUD operations, using `ChromaDB`'s `delete` method with the vector ID. This shows the straightforward nature of `ChromaDB`'s API for vector management.",
      "file": "dimos/agents/memory/chroma_impl.py",
      "highlight": [
        {
          "start": 82,
          "end": 86
        }
      ],
      "title": "",
      "id": "69108",
      "hideAreas": []
    },
    {
      "type": "highlight",
      "description": "The `OpenAISemanticMemory` class extends the base class to integrate with OpenAI's embedding API. The constructor accepts key parameters: the `embedding model name` and `dimensions`, providing flexibility in choosing different `OpenAI embedding models`.",
      "file": "dimos/agents/memory/chroma_impl.py",
      "highlight": [
        {
          "start": 89,
          "end": 102
        }
      ],
      "title": "",
      "id": "69109",
      "hideAreas": []
    },
    {
      "type": "highlight",
      "description": "The OpenAI `create` method shows the integration pattern: retrieve the API key from environment variables (lines 107-109), initialize the `OpenAIEmbeddings` object with the specified model and dimensions (lines 112-116), and create the `ChromaDB` connection with the embedding function and cosine similarity configuration (lines 119-123).",
      "file": "dimos/agents/memory/chroma_impl.py",
      "highlight": [
        {
          "start": 104,
          "end": 123
        }
      ],
      "title": "",
      "id": "69110",
      "hideAreas": []
    },
    {
      "type": "highlight",
      "description": "The `LocalSemanticMemory` class provides an alternative that uses local sentence transformer models instead of external APIs. The constructor imports `SentenceTransformer` and accepts a model name, defaulting to a commonly used lightweight model.",
      "file": "dimos/agents/memory/chroma_impl.py",
      "highlight": [
        {
          "start": 126,
          "end": 139
        }
      ],
      "title": "",
      "id": "69111",
      "hideAreas": []
    },
    {
      "type": "highlight",
      "description": "The local implementation's `create` method starts by detecting available hardware. It checks for `CUDA` availability and loads the sentence transformer model on the appropriate device, taking advantage of GPU acceleration if it's available.",
      "file": "dimos/agents/memory/chroma_impl.py",
      "highlight": [
        {
          "start": 141,
          "end": 147
        }
      ],
      "title": "",
      "id": "69112",
      "hideAreas": []
    },
    {
      "type": "highlight",
      "description": "The `SentenceTransformerEmbeddings` wrapper class solves an interface compatibility problem. `ChromaDB` expects separate `embed_query` and `embed_documents` methods, but `SentenceTransformer` uses a single `encode` method. This wrapper adapts the interface by implementing both required methods (lines 154-156 and 158-160) that call the underlying `encode` method.",
      "file": "dimos/agents/memory/chroma_impl.py",
      "highlight": [
        {
          "start": 150,
          "end": 161
        }
      ],
      "title": "",
      "id": "69113",
      "hideAreas": []
    },
    {
      "type": "mcq",
      "description": "In the `LocalSemanticMemory` implementation, what is the primary purpose of the `SentenceTransformerEmbeddings` wrapper class (lines 150-160)?\n\nOptions:\n\n A). To optimize embedding generation by automatically selecting between CPU and CUDA for the sentence transformer model.\n\nB). To adapt the single `encode` method of the `SentenceTransformer` model to the `embed_query` and `embed_documents` methods required by ChromaDB.\n\nC). To normalize and convert embedding vectors from PyTorch tensors into JSON-serializable lists for storage.\n\n\nCorrect: B). To adapt the single `encode` method of the `SentenceTransformer` model to the `embed_query` and `embed_documents` methods required by ChromaDB.\n\nExplanation: The correct answer is that the wrapper adapts the `SentenceTransformer` interface to what ChromaDB expects. ChromaDB's `embedding_function` requires an object with both `embed_query` and `embed_documents` methods. The `sentence-transformers` library provides a single `encode` method. The wrapper class bridges this gap. While device selection (CUDA/CPU) and data type conversion (`.tolist()`) do occur, they are not the primary purpose of the wrapper class itself; the device is selected before the wrapper is instantiated, and the conversion is an implementation detail of the adaptation.",
      "title": "",
      "id": "69115",
      "text": "In the `LocalSemanticMemory` implementation, what is the primary purpose of the `SentenceTransformerEmbeddings` wrapper class (lines 150-160)?",
      "answers": [
        "To optimize embedding generation by automatically selecting between CPU and CUDA for the sentence transformer model.",
        "To adapt the single `encode` method of the `SentenceTransformer` model to the `embed_query` and `embed_documents` methods required by ChromaDB.",
        "To normalize and convert embedding vectors from PyTorch tensors into JSON-serializable lists for storage."
      ],
      "correct": 1,
      "explanation": "The correct answer is that the wrapper adapts the `SentenceTransformer` interface to what ChromaDB expects. ChromaDB's `embedding_function` requires an object with both `embed_query` and `embed_documents` methods. The `sentence-transformers` library provides a single `encode` method. The wrapper class bridges this gap. While device selection (CUDA/CPU) and data type conversion (`.tolist()`) do occur, they are not the primary purpose of the wrapper class itself; the device is selected before the wrapper is instantiated, and the conversion is an implementation detail of the adaptation."
    },
    {
      "type": "highlight",
      "description": "The final step creates the **wrapper** instance and initializes the `ChromaDB` connection. This demonstrates the **adapter pattern** in action - the **wrapper** allows the local `sentence transformer` to work seamlessly with `ChromaDB`'s expected interface, using the same **cosine similarity** configuration as the `OpenAI` implementation.",
      "file": "dimos/agents/memory/chroma_impl.py",
      "highlight": [
        {
          "start": 162,
          "end": 170
        }
      ],
      "title": "",
      "id": "69114",
      "hideAreas": []
    }
  ]
}